{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a16c943-d981-4ab7-9093-289ff167ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from itertools import pairwise, product\n",
    "from more_itertools import windowed\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cd6637-f87b-4952-ba90-14be020108cd",
   "metadata": {},
   "source": [
    "Download corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94ae475-874a-478e-9fd2-c1b19457f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\KYRIAKOS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae5818e-4de7-42da-b4f0-9995047ed4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = brown.sents(categories = 'editorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91f7359-a735-46d0-adb3-14e8f4830b11",
   "metadata": {},
   "source": [
    "Preprocess text and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b285cdd-4f1e-44d3-bf9e-61bc236ec946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sents):\n",
    "    # Preprocess: lowercase + keep only words that are letters, comma, or period\n",
    "    clean = [\n",
    "        [w.lower() for w in sent if re.fullmatch(r'[a-zA-Z]+|[,.]', w)]\n",
    "        for sent in sents\n",
    "    ]\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8dadcf0-1647-4c8f-877c-7a7389006c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterLen(sents, lowThr, upperThr):\n",
    "    return [s for s in sents if lowThr <= len(s) <= upperThr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7b14b0-2b8e-4312-b14a-f77cde21d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterFreq(sents, threshold):\n",
    "    \"\"\"\n",
    "    Keep only tokens that appear >= min_freq times in the provided portion.\n",
    "    Others are dropped.\n",
    "    \"\"\"\n",
    "    # Flatten and count\n",
    "    counts = Counter(w for sent in sents for w in sent)\n",
    "    # Build vocabulary\n",
    "    vocab = {w for w, c in counts.items() if c >= threshold}\n",
    "    # Filter sentences\n",
    "    filteredSents = [[w if w in vocab else '<UNK>' for w in sent] for sent in sents]\n",
    "    return filteredSents, vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035ff3e-a1e4-4b57-9d31-1919ec9b80b5",
   "metadata": {},
   "source": [
    "Split into subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23de280b-9fb3-4822-8074-9227cbbf9fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSubsets(data):\n",
    "    random.seed(31)\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    trainSize = int(0.8 * len(data))\n",
    "    valSize = int(0.1 * len(data))\n",
    "    \n",
    "    train = data[:trainSize]\n",
    "    val = data[trainSize:trainSize + valSize]\n",
    "    test = data[trainSize + valSize:]\n",
    "    \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32cebc9-419c-4289-bba9-92c7e97454c3",
   "metadata": {},
   "source": [
    "Build the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a31fea-a606-4391-b141-466b52fe5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLM:\n",
    "    def __init__(self, sents, vocab, alpha):\n",
    "        self.sents = sents\n",
    "        self.vocab = vocab\n",
    "        self.alpha = alpha\n",
    "        self.uniCounter = Counter()\n",
    "        self.biCounter = Counter()\n",
    "        self.buildCounts()\n",
    "    \n",
    "    def buildCounts(self):\n",
    "        \"\"\"\n",
    "        Takes tokenized sentences.\n",
    "        Populates unigram and bigram counters with <START>/<END> padding.\n",
    "        \"\"\"\n",
    "        for sent in self.sents:\n",
    "            paddedSent = ['<START>'] + sent + ['<END>']\n",
    "            self.uniCounter.update([gram for gram in ngrams(paddedSent, 1)])\n",
    "            self.biCounter.update([gram for gram in ngrams(paddedSent, 2)])\n",
    "\n",
    "    def prob(self, w1, w2):\n",
    "        uniCount = self.uniCounter.get((w1,), 0)\n",
    "        biCount = self.biCounter.get((w1, w2), 0)\n",
    "        V = len(self.vocab)\n",
    "        \n",
    "        return (biCount + self.alpha) / (uniCount + self.alpha * V)\n",
    "\n",
    "    def crossEntropyAndPerplexity(self, sents):\n",
    "        sumLogProb = 0\n",
    "        nBigrams = 0\n",
    "        for sent in sents:\n",
    "            paddedSent = ['<START>'] + sent + ['<END>']\n",
    "            for w1, w2 in pairwise(paddedSent):\n",
    "                sumLogProb += math.log2(self.prob(w1, w2))\n",
    "                nBigrams += 1\n",
    "        hc = -sumLogProb / nBigrams\n",
    "        ppl = 2 ** hc\n",
    "        \n",
    "        return hc, ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e4ec7b3-433f-453d-b4af-4fa9c17141ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramLM:\n",
    "    def __init__(self, sents, vocab, alpha):\n",
    "        self.sents = sents\n",
    "        self.vocab = vocab\n",
    "        self.alpha = alpha\n",
    "        self.biCounter = Counter()\n",
    "        self.triCounter = Counter()\n",
    "        self.buildCounts()\n",
    "    \n",
    "    def buildCounts(self):\n",
    "        \"\"\"\n",
    "        Takes tokenized sentences.\n",
    "        Populates bigram and trigram counters with <START1>/<START2>/<END> padding.\n",
    "        \"\"\"\n",
    "        for sent in self.sents:\n",
    "            paddedSent = ['<START1>', '<START2>'] + sent + ['<END>']\n",
    "            self.biCounter.update([gram for gram in ngrams(paddedSent, 2)])\n",
    "            self.triCounter.update([gram for gram in ngrams(paddedSent, 3)])\n",
    "\n",
    "    def prob(self, w1, w2, w3):\n",
    "        biCount = self.biCounter.get((w1, w2), 0)\n",
    "        triCount = self.triCounter.get((w1, w2, w3), 0)\n",
    "        V = len(self.vocab)\n",
    "        \n",
    "        return (triCount + self.alpha) / (biCount + self.alpha * V)\n",
    "    \n",
    "    def crossEntropyAndPerplexity(self, sents):\n",
    "        sumLogProb = 0\n",
    "        nTrigrams = 0\n",
    "        for sent in sents:\n",
    "            paddedSent = ['<START1>', '<START2>'] + sent + ['<END>']\n",
    "            for w1, w2, w3 in windowed(paddedSent, 3):\n",
    "                sumLogProb += math.log2(self.prob(w1, w2, w3))\n",
    "                nTrigrams += 1\n",
    "        hc = -sumLogProb / nTrigrams\n",
    "        ppl = 2 ** hc\n",
    "        return hc, ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9cd473c-a56f-46ce-a135-1d6cb4a64c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterpolatedLM:\n",
    "    def __init__(self, sents, vocab, alphaB, alphaT, l):\n",
    "        self.sents = sents\n",
    "        self.bigram = BigramLM(sents, vocab, alphaB)\n",
    "        self.trigram = TrigramLM(sents, vocab, alphaT)\n",
    "        self.l = l\n",
    "    \n",
    "    def prob(self, w1, w2, w3):\n",
    "        \"\"\"\n",
    "        Interpolated probability of w3 given w1,w2.\n",
    "        \"\"\"\n",
    "        triProb = self.trigram.prob(w1, w2, w3)   # from trigram counts\n",
    "        biProb = self.bigram.prob(w2, w3)         # from bigram counts\n",
    "        return self.l * triProb + (1 - self.l) * biProb\n",
    "\n",
    "    def crossEntropyAndPerplexity(self, sents):\n",
    "        sumLogProb = 0\n",
    "        ngramCount = 0\n",
    "        \n",
    "        for sent in sents:\n",
    "            # Add two start tokens for trigrams\n",
    "            sent = ['<START>', '<START>'] + sent + ['<END>']\n",
    "            \n",
    "            for w1, w2, w3 in windowed(sent, 3):\n",
    "                trigramProb = self.trigram.prob(w1, w2, w3)\n",
    "                bigramProb = self.bigram.prob(w2, w3)\n",
    "                \n",
    "                # Interpolation: λ * P(trigram) + (1-λ) * P(bigram)\n",
    "                interpolatedProb = self.l * trigramProb + (1 - self.l) * bigramProb\n",
    "                sumLogProb += math.log2(interpolatedProb)\n",
    "                ngramCount += 1\n",
    "        \n",
    "        crossEntropy = -sumLogProb / ngramCount\n",
    "        perplexity = math.pow(2, crossEntropy)\n",
    "        return crossEntropy, perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36df823-6c9c-4c44-8dfe-d450aafd1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = preprocess(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18afde79-affa-4725-a37d-1dbb8675cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = splitSubsets(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f5aa70d-4d18-4380-9a72-32ff9cf3181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fltrain = filterLen(train, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3667ad7a-1144-48ef-8f97-9625f510a591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2397"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dcfbfcc-1ced-4941-a769-a9df102f2d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b1b1d00-a078-43b6-86bb-4389eed05a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsents, vocab = filterFreq(fltrain, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803cc040-3302-4532-8f78-96910a85c449",
   "metadata": {},
   "source": [
    "Evaluate individually (cross entropy) with fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3661e11e-1ce9-4f1c-81d5-5cb547de3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgrm = BigramLM(fsents, vocab, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89dae1ef-353a-4a16-883d-d78fe962e8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.032173231620663, 130.88656718033667)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgrm.crossEntropyAndPerplexity(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a40f336c-3c7a-45b0-aebd-4156a1460151",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgrm = TrigramLM(fsents, vocab, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba77b1ce-2be4-4c9a-b5d5-3ebd1ff34302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.3277080179523795, 160.64229975586332)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgrm.crossEntropyAndPerplexity(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c6fe7d3-4f80-4654-8443-170cadd91ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = InterpolatedLM(fsents, vocab, 2, 3, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0577481-d47c-439b-9c80-505c00cff835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.996003193004343, 127.64588268142266)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter.crossEntropyAndPerplexity(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffdf07-28f5-4c5d-88b1-f339e928ca8d",
   "metadata": {},
   "source": [
    "Explore parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65619f67-471b-4c4e-b217-b2070aad8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "candAlpha = [0.5, 1, 2, 3, 5, 10, 50]\n",
    "candThreshold = [5, 10, 15, 20, 30]\n",
    "candLambda = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "candidates = [candAlpha, candThreshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "753fddbd-7084-40a2-bdc5-910ab611ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(model):\n",
    "    optimalCE = math.inf\n",
    "    for a, t in product(*candidates):\n",
    "        fsents, vocab = filterFreq(fltrain, t)\n",
    "        ngrm = model(fsents, vocab, a)\n",
    "        ce, _ = ngrm.crossEntropyAndPerplexity(val)\n",
    "        if(ce < optimalCE):\n",
    "            optimalCE = ce\n",
    "            optimalA = a\n",
    "            optimalT = t\n",
    "\n",
    "    return optimalA, optimalT, optimalCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a7bf640-ca31-47fa-8bfc-49f818236a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 30, 5.576321052454329)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune(BigramLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5a11d45-1a4b-400b-8ad3-522f52f3bbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 30, 5.7246604337433356)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune(TrigramLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6874fb8b-46f4-4d18-8d22-f66e75023e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 5.581870145212111\n"
     ]
    }
   ],
   "source": [
    "fsents, vocab = filterFreq(fltrain, 30)\n",
    "optimalCE = math.inf\n",
    "for l in candLambda:\n",
    "    inter = InterpolatedLM(fsents, vocab, 10, 5, l)\n",
    "    ce, _ = inter.crossEntropyAndPerplexity(val)\n",
    "    if(ce < optimalCE):\n",
    "        optimalCE = ce\n",
    "        optimalL = l\n",
    "\n",
    "print(optimalL, optimalCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ed149-c25d-42b0-95da-da7037bf197c",
   "metadata": {},
   "source": [
    "Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2470e00e-6242-407b-bfb8-61f1bce37be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsents, vocab = filterFreq(fltrain, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac73c4c7-c5d9-4b6c-b860-4d63ea2d294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgrm = BigramLM(fsents, vocab, 10)\n",
    "tgrm = TrigramLM(fsents, vocab, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0d93e34-065c-4ac9-90ea-18d53e5cb778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.038295003468157, 131.44313670503732)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgrm.crossEntropyAndPerplexity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c767f34-e386-4af0-b508-0bd1678aacca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.334055202542064, 161.35060784129482)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgrm.crossEntropyAndPerplexity(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396fb2f-65b3-465a-8d23-21dbdb92805d",
   "metadata": {},
   "source": [
    "Sentence completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fad4fc3-36e8-43f8-b5cb-73cb4ac6d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "\n",
    "def score(sentence, model):\n",
    "    logProb = 0.0\n",
    "    for i in range(1, len(sentence)):\n",
    "        w1, w2 = sentence[i-1], sentence[i]\n",
    "        prob = model.prob(w1, w2)\n",
    "        logProb += math.log(prob, 2)\n",
    "    return logProb\n",
    "\n",
    "def beamSearch(sentence, model, depth, k):\n",
    "    q = Queue()\n",
    "    finalResults = []\n",
    "    q.put((0, sentence)) \n",
    "\n",
    "    while not q.empty():\n",
    "        d, s = q.get()\n",
    "        if(d == depth):\n",
    "            finalResults.append(s)\n",
    "            continue\n",
    "\n",
    "        candidateSentences = []\n",
    "        for w in model.vocab:\n",
    "            if(w in {'<UNK>', '<START>', '<START1>', '<START2>'}):\n",
    "                continue\n",
    "            if(w == s[-1]): ## Prevent consecutive duplicates\n",
    "                continue\n",
    "            candidateSentences.append(s + [w])\n",
    "\n",
    "        ## Keep top k candidates by score\n",
    "        topK = sorted(candidateSentences, key=lambda x: score(x, model), reverse = True)[:k]\n",
    "\n",
    "        ## Add next depth candidates to queue\n",
    "        for cand in topK:\n",
    "            q.put((d + 1, cand))\n",
    "\n",
    "    ## Return final sentences as strings\n",
    "    finalResults = sorted(finalResults, key=lambda x: score(x, model), reverse = True)[:k]\n",
    "    return list(map(lambda x: ' '.join(x), finalResults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dce7e8d7-d96e-429b-8dbf-68ac610aba96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I would like to commend the editor of the',\n",
       " 'I would like to commend the most of the',\n",
       " 'I would like to commend the first of the',\n",
       " 'I would like to commend the editor of a',\n",
       " 'I would like to commend the editor of course',\n",
       " 'I would like to commend the editor of his',\n",
       " 'I would like to commend the new , the']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ['I', 'would', 'like', 'to', 'commend', 'the']\n",
    "beamSearch(prompt, bgrm, depth = 3, k = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "084c5350-b8bb-4dc5-a1cd-7a3ff98b6244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I would like to commend the editor of the editor of',\n",
       " 'I would like to commend the editor of the new york',\n",
       " 'I would like to commend the editor of the editor old',\n",
       " 'I would like to commend the editor of the editor i',\n",
       " 'I would like to commend the editor of the editor being']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ['I', 'would', 'like', 'to', 'commend', 'the']\n",
    "beamSearch(prompt, bgrm, depth = 5, k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a6b0f63-7905-47ae-8895-86e6b5575149",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [s[0:5] for s in test][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "164556e7-ec54-45bf-b997-d7fc7773148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when east germans fled to the editor of\n",
      "when east germans fled to the new york\n",
      "when east germans fled to have to the\n",
      "when east germans fled to the editor old\n",
      "when east germans fled to the editor i\n",
      "it was part of a good , the\n",
      "it was part of a man to the\n",
      "it was part of a good , and\n",
      "it was part of a man , the\n",
      "it was part of a great , the\n",
      "yet they supported the eisenhower man to the\n",
      "yet they supported the eisenhower county in the\n",
      "yet they supported the eisenhower county , the\n",
      "yet they supported the eisenhower man , the\n",
      "yet they supported the eisenhower old , the\n",
      "the state department tacitly rejected man to the\n",
      "the state department tacitly rejected county in the\n",
      "the state department tacitly rejected county , the\n",
      "the state department tacitly rejected man , the\n",
      "the state department tacitly rejected old , the\n",
      "certainly , the meaning is in the editor\n",
      "certainly , the meaning is in the inquirer\n",
      "certainly , the meaning is in the new\n",
      "certainly , the meaning is the editor of\n",
      "certainly , the meaning is in the first\n",
      "undertaken by american scholars , the editor of\n",
      "undertaken by american scholars , but it is\n",
      "undertaken by american scholars , and the editor\n",
      "undertaken by american scholars , he is a\n",
      "undertaken by american scholars , and the inquirer\n",
      "the relatively few communities that it is a\n",
      "the relatively few communities that it is the\n",
      "the relatively few communities that is in the\n",
      "the relatively few communities that it is not\n",
      "the relatively few communities that it is no\n",
      "if it is not enough of the editor\n",
      "if it is not enough of the inquirer\n",
      "if it is not enough of the new\n",
      "if it is not enough to the editor\n",
      "if it is not enough of the first\n",
      "please do put more pictures man to the\n",
      "please do put more pictures county in the\n",
      "please do put more pictures county , the\n",
      "please do put more pictures man , the\n",
      "please do put more pictures old , the\n",
      "negligence in garbage and rubbish man to the\n",
      "negligence in garbage and rubbish county in the\n",
      "negligence in garbage and rubbish county , the\n",
      "negligence in garbage and rubbish man , the\n",
      "negligence in garbage and rubbish old , the\n"
     ]
    }
   ],
   "source": [
    "for p in prompts:\n",
    "    print(*beamSearch(p, bgrm, depth = 3, k = 5), sep = '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
