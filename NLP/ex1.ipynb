{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a16c943-d981-4ab7-9093-289ff167ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from itertools import pairwise, product\n",
    "from more_itertools import windowed\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cd6637-f87b-4952-ba90-14be020108cd",
   "metadata": {},
   "source": [
    "Download corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94ae475-874a-478e-9fd2-c1b19457f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\KYRIAKOS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae5818e-4de7-42da-b4f0-9995047ed4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = brown.sents(categories = 'editorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91f7359-a735-46d0-adb3-14e8f4830b11",
   "metadata": {},
   "source": [
    "Preprocess text and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b285cdd-4f1e-44d3-bf9e-61bc236ec946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sents):\n",
    "    # Preprocess: lowercase + keep only words that are letters, comma, or period\n",
    "    clean = [\n",
    "        [w.lower() for w in sent if re.fullmatch(r'[a-zA-Z]+|[,.]', w)]\n",
    "        for sent in sents\n",
    "    ]\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8dadcf0-1647-4c8f-877c-7a7389006c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterLen(sents, lowThr, upperThr):\n",
    "    return [s for s in sents if lowThr <= len(s) <= upperThr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7b14b0-2b8e-4312-b14a-f77cde21d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterFreq(sents, threshold):\n",
    "    \"\"\"\n",
    "    Keep only tokens that appear >= min_freq times in the provided portion.\n",
    "    Others are dropped.\n",
    "    \"\"\"\n",
    "    # Flatten and count\n",
    "    counts = Counter(w for sent in sents for w in sent)\n",
    "    # Build vocabulary\n",
    "    vocab = {w for w, c in counts.items() if c >= threshold}\n",
    "    # Filter sentences\n",
    "    filteredSents = [[w if w in vocab else '<UNK>' for w in sent] for sent in sents]\n",
    "    return filteredSents, vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035ff3e-a1e4-4b57-9d31-1919ec9b80b5",
   "metadata": {},
   "source": [
    "Split into subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23de280b-9fb3-4822-8074-9227cbbf9fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSubsets(data):\n",
    "    random.seed(31)\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    trainSize = int(0.8 * len(data))\n",
    "    valSize = int(0.1 * len(data))\n",
    "    \n",
    "    train = data[:trainSize]\n",
    "    val = data[trainSize:trainSize + valSize]\n",
    "    test = data[trainSize + valSize:]\n",
    "    \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32cebc9-419c-4289-bba9-92c7e97454c3",
   "metadata": {},
   "source": [
    "Build the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a31fea-a606-4391-b141-466b52fe5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLM:\n",
    "    def __init__(self, sents, vocab, alpha):\n",
    "        self.sents = sents\n",
    "        self.vocab = vocab\n",
    "        self.alpha = alpha\n",
    "        self.uniCounter = Counter()\n",
    "        self.biCounter = Counter()\n",
    "        self.buildCounts()\n",
    "    \n",
    "    def buildCounts(self):\n",
    "        \"\"\"\n",
    "        Takes tokenized sentences.\n",
    "        Populates unigram and bigram counters with <START>/<END> padding.\n",
    "        \"\"\"\n",
    "        for sent in self.sents:\n",
    "            paddedSent = ['<START>'] + sent + ['<END>']\n",
    "            self.uniCounter.update([gram for gram in ngrams(paddedSent, 1)])\n",
    "            self.biCounter.update([gram for gram in ngrams(paddedSent, 2)])\n",
    "\n",
    "    def prob(self, w1, w2):\n",
    "        uniCount = self.uniCounter.get((w1,), 0)\n",
    "        biCount = self.biCounter.get((w1, w2), 0)\n",
    "        V = len(self.vocab)\n",
    "        \n",
    "        return (biCount + self.alpha) / (uniCount + self.alpha * V)\n",
    "\n",
    "    def crossEntropyAndPerplexity(self, sents):\n",
    "        sumLogProb = 0\n",
    "        nBigrams = 0\n",
    "        for sent in sents:\n",
    "            paddedSent = ['<START>'] + sent + ['<END>']\n",
    "            for w1, w2 in pairwise(paddedSent):\n",
    "                sumLogProb += math.log2(self.prob(w1, w2))\n",
    "                nBigrams += 1\n",
    "        hc = -sumLogProb / nBigrams\n",
    "        ppl = 2 ** hc\n",
    "        \n",
    "        return hc, ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e4ec7b3-433f-453d-b4af-4fa9c17141ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramLM:\n",
    "    def __init__(self, sents, vocab, alpha):\n",
    "        self.sents = sents\n",
    "        self.vocab = vocab\n",
    "        self.alpha = alpha\n",
    "        self.biCounter = Counter()\n",
    "        self.triCounter = Counter()\n",
    "        self.buildCounts()\n",
    "    \n",
    "    def buildCounts(self):\n",
    "        \"\"\"\n",
    "        Takes tokenized sentences.\n",
    "        Populates bigram and trigram counters with <START1>/<START2>/<END> padding.\n",
    "        \"\"\"\n",
    "        for sent in self.sents:\n",
    "            paddedSent = ['<START1>', '<START2>'] + sent + ['<END>']\n",
    "            self.biCounter.update([gram for gram in ngrams(paddedSent, 2)])\n",
    "            self.triCounter.update([gram for gram in ngrams(paddedSent, 3)])\n",
    "\n",
    "    def prob(self, w1, w2, w3):\n",
    "        biCount = self.biCounter.get((w1, w2), 0)\n",
    "        triCount = self.triCounter.get((w1, w2, w3), 0)\n",
    "        V = len(self.vocab)\n",
    "        \n",
    "        return (triCount + self.alpha) / (biCount + self.alpha * V)\n",
    "    \n",
    "    def crossEntropyAndPerplexity(self, sents):\n",
    "        sumLogProb = 0\n",
    "        nTrigrams = 0\n",
    "        for sent in sents:\n",
    "            paddedSent = ['<START1>', '<START2>'] + sent + ['<END>']\n",
    "            for w1, w2, w3 in windowed(paddedSent, 3):\n",
    "                sumLogProb += math.log2(self.prob(w1, w2, w3))\n",
    "                nTrigrams += 1\n",
    "        hc = -sumLogProb / nTrigrams\n",
    "        ppl = 2 ** hc\n",
    "        return hc, ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9cd473c-a56f-46ce-a135-1d6cb4a64c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterpolatedLM:\n",
    "    def __init__(self, sents, vocab, alphaB, alphaT, l):\n",
    "        self.sents = sents\n",
    "        self.bigram = BigramLM(sents, vocab, alphaB)\n",
    "        self.trigram = TrigramLM(sents, vocab, alphaT)\n",
    "        self.l = l\n",
    "    \n",
    "    def prob(self, w1, w2, w3):\n",
    "        \"\"\"\n",
    "        Interpolated probability of w3 given w1,w2.\n",
    "        \"\"\"\n",
    "        triProb = self.trigram.prob(w1, w2, w3)   # from trigram counts\n",
    "        biProb = self.bigram.prob(w2, w3)         # from bigram counts\n",
    "        return self.l * triProb + (1 - self.l) * biProb\n",
    "\n",
    "    def crossEntropyAndPerplexity(self, sents):\n",
    "        sumLogProb = 0\n",
    "        ngramCount = 0\n",
    "        \n",
    "        for sent in sents:\n",
    "            # Add two start tokens for trigrams\n",
    "            sent = ['<START>', '<START>'] + sent + ['<END>']\n",
    "            \n",
    "            for w1, w2, w3 in windowed(sent, 3):\n",
    "                trigramProb = self.trigram.prob(w1, w2, w3)\n",
    "                bigramProb = self.bigram.prob(w2, w3)\n",
    "                \n",
    "                # Interpolation: λ * P(trigram) + (1-λ) * P(bigram)\n",
    "                interpolatedProb = self.l * trigramProb + (1 - self.l) * bigramProb\n",
    "                sumLogProb += math.log2(interpolatedProb)\n",
    "                ngramCount += 1\n",
    "        \n",
    "        crossEntropy = -sumLogProb / ngramCount\n",
    "        perplexity = math.pow(2, crossEntropy)\n",
    "        return crossEntropy, perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36df823-6c9c-4c44-8dfe-d450aafd1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = preprocess(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18afde79-affa-4725-a37d-1dbb8675cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = splitSubsets(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f5aa70d-4d18-4380-9a72-32ff9cf3181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fltrain = filterLen(train, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3667ad7a-1144-48ef-8f97-9625f510a591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2397"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dcfbfcc-1ced-4941-a769-a9df102f2d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b1b1d00-a078-43b6-86bb-4389eed05a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsents, vocab = filterFreq(fltrain, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803cc040-3302-4532-8f78-96910a85c449",
   "metadata": {},
   "source": [
    "Evaluate individually (cross entropy) with fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3661e11e-1ce9-4f1c-81d5-5cb547de3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgrm = BigramLM(fsents, vocab, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89dae1ef-353a-4a16-883d-d78fe962e8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.032173231620663, 130.88656718033667)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgrm.crossEntropyAndPerplexity(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a40f336c-3c7a-45b0-aebd-4156a1460151",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgrm = TrigramLM(fsents, vocab, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba77b1ce-2be4-4c9a-b5d5-3ebd1ff34302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.3277080179523795, 160.64229975586332)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgrm.crossEntropyAndPerplexity(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c6fe7d3-4f80-4654-8443-170cadd91ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = InterpolatedLM(fsents, vocab, 2, 3, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0577481-d47c-439b-9c80-505c00cff835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.996003193004343, 127.64588268142266)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter.crossEntropyAndPerplexity(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffdf07-28f5-4c5d-88b1-f339e928ca8d",
   "metadata": {},
   "source": [
    "Explore parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65619f67-471b-4c4e-b217-b2070aad8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "candAlpha = [0.5, 1, 2, 3, 5, 10, 50]\n",
    "candThreshold = [5, 10, 15, 20, 30]\n",
    "candLambda = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "candidates = [candAlpha, candThreshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "753fddbd-7084-40a2-bdc5-910ab611ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(model):\n",
    "    optimalCE = math.inf\n",
    "    for a, t in product(*candidates):\n",
    "        fsents, vocab = filterFreq(fltrain, t)\n",
    "        ngrm = model(fsents, vocab, a)\n",
    "        ce, _ = ngrm.crossEntropyAndPerplexity(val)\n",
    "        if(ce < optimalCE):\n",
    "            optimalCE = ce\n",
    "            optimalA = a\n",
    "            optimalT = t\n",
    "\n",
    "    return optimalA, optimalT, optimalCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a7bf640-ca31-47fa-8bfc-49f818236a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 30, 5.576321052454329)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune(BigramLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5a11d45-1a4b-400b-8ad3-522f52f3bbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 30, 5.7246604337433356)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune(TrigramLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6874fb8b-46f4-4d18-8d22-f66e75023e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 5.581870145212111\n"
     ]
    }
   ],
   "source": [
    "fsents, vocab = filterFreq(fltrain, 30)\n",
    "optimalCE = math.inf\n",
    "for l in candLambda:\n",
    "    inter = InterpolatedLM(fsents, vocab, 10, 5, l)\n",
    "    ce, _ = inter.crossEntropyAndPerplexity(val)\n",
    "    if(ce < optimalCE):\n",
    "        optimalCE = ce\n",
    "        optimalL = l\n",
    "\n",
    "print(optimalL, optimalCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ed149-c25d-42b0-95da-da7037bf197c",
   "metadata": {},
   "source": [
    "Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2470e00e-6242-407b-bfb8-61f1bce37be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsents, vocab = filterFreq(fltrain, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac73c4c7-c5d9-4b6c-b860-4d63ea2d294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgrm = BigramLM(fsents, vocab, 10)\n",
    "tgrm = TrigramLM(fsents, vocab, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0d93e34-065c-4ac9-90ea-18d53e5cb778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.038295003468157, 131.44313670503732)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgrm.crossEntropyAndPerplexity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c767f34-e386-4af0-b508-0bd1678aacca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.334055202542064, 161.35060784129482)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgrm.crossEntropyAndPerplexity(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396fb2f-65b3-465a-8d23-21dbdb92805d",
   "metadata": {},
   "source": [
    "Sentence completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e361166f-2887-4665-8cff-02b83e32849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(model, state):\n",
    "    \"\"\"\n",
    "    Generate possible next words from the current state.\n",
    "    For bigram: use last word; for trigram/interpolated: use last 1-2 words.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    last_word = state[-1] if state else '<START>'\n",
    "    for word in model.vocab:\n",
    "        if word in {'<UNK>', '<START>', '<START1>', '<START2>'}:\n",
    "            continue\n",
    "        # enforce no consecutive duplicates\n",
    "        if state and word == state[-1]:\n",
    "            continue\n",
    "        candidates.append(state + [word])\n",
    "    return candidates\n",
    "\n",
    "def score_state(model, state):\n",
    "    \"\"\"\n",
    "    Score a sequence using the model.\n",
    "    Uses product of probabilities (or log sum for numerical stability).\n",
    "    \"\"\"\n",
    "    log_prob = 0.0\n",
    "    for i in range(1, len(state)):\n",
    "        w1, w2 = state[i-2], state[i-1] if i >= 2 else ('<START>', state[i-1])\n",
    "        w3 = state[i]\n",
    "        try:\n",
    "            p = model.prob(w1, w2, w3)  # Interpolated or trigram\n",
    "        except TypeError:\n",
    "            p = model.prob(w2, w3)  # Bigram fallback\n",
    "        if p <= 0:\n",
    "            p = 1e-12  # avoid log(0)\n",
    "        log_prob += math.log(p)\n",
    "    return log_prob  # higher is better (sum of logs)\n",
    "\n",
    "def beam_search_decode(model, initial_state, max_depth=10, beam_width=5):\n",
    "    \"\"\"\n",
    "    Beam search decoding using the model.\n",
    "    Returns the best sequence according to log-probability.\n",
    "    \"\"\"\n",
    "    candidates = [(initial_state, 0.0)]  # (sequence, log_prob)\n",
    "\n",
    "    for depth in range(max_depth):\n",
    "        new_candidates = []\n",
    "        for seq, logp in candidates:\n",
    "            for next_seq in generate_candidates(model, seq):\n",
    "                new_logp = logp + score_state(model, next_seq)\n",
    "                new_candidates.append((next_seq, new_logp))\n",
    "        # Sort by log probability descending\n",
    "        new_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        candidates = new_candidates[:beam_width]\n",
    "\n",
    "    best_seq, best_logp = max(candidates, key=lambda x: x[1])\n",
    "    return best_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a6b0f63-7905-47ae-8895-86e6b5575149",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [s[0:5] for s in test][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a15e6b8-fda0-4d8d-9410-5f7eae7dc533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would like to commend the editor of the\n"
     ]
    }
   ],
   "source": [
    "prompt = ['I', 'would', 'like', 'to', 'commend', 'the']\n",
    "best_seq = beam_search_decode(bgrm, prompt, max_depth=3, beam_width=5)\n",
    "print(' '.join(best_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "164556e7-ec54-45bf-b997-d7fc7773148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when east germans fled to the editor of the editor\n",
      "it was part of a good , the editor of\n",
      "yet they supported the eisenhower about the editor of the\n",
      "the state department tacitly rejected about the editor of the\n",
      "certainly , the meaning is a good , the editor\n",
      "undertaken by american scholars , the editor of the editor\n",
      "the relatively few communities that it is a good ,\n",
      "if it is not enough of the editor of the\n",
      "please do put more pictures about the editor of the\n",
      "negligence in garbage and rubbish about the editor of the\n"
     ]
    }
   ],
   "source": [
    "for p in prompts:\n",
    "    print(' '.join(beam_search_decode(bgrm, p, max_depth=5, beam_width=5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
